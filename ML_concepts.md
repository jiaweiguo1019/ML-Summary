# ML Concepts

在计算机系统中，“经验”通常以“数据”形式存在，因此，机器学习所研究的主要内容，是关于在计算机上从数据中产生“模型”的算法，即学习算法（learning algorithm）。有了学习算法，我们把**经验**数据提供给`它`，它就能基于这些数据产生模型；在面对新的情况时，模型会给我们提供相应的判断。

数据集
示例、样本
属性、特征
属性值

属性张成的空间称为“属性空间”、“样本空间”或“输入空间”。
由于空间中的每个点对应一个坐标向量，因此我们也把**一个示例**称为一个“**特征向量**”。

从数据学得模型的过程称为“学习”或“训练”，这个过程是通过执行**某个**学习算法来完成。
学得模型对应了关于数据的某种潜在的规律，因此亦称“假设”；这种潜在规律自身，则称为“真相”或“真实”，学习过程就是为了找出或逼近真相。

标记
有了标记信息的示例，则称为“样例”
标记的集合：“样本空间”或“输出空间”

通常**假设**样本空间中全体样本服从一个未知的“分布” $\mathcal{D}$，我们获得的每个样本都是独立地从这个分布上采样获得的，即“独立同分布”

## 假设空间

归纳（induction）：特殊到一般
演绎（deduction）：一般到特殊

狭义的归纳学习：“概念学习”或“概念形成”

我们可以把学习过程看作一个在**所有**假设组成的空间中进行搜索的过程，搜索目标是找到与训练集“匹配”（fit）的假设。

现实问题中我们常面临很大的假设空间，但学习过程是基于有限样本训练集进行的，因为，可能有多个假设与训练集一致，即存在着一个与训练集一致的“假设集合”，我们称之为“**版本空间**”（version space）

## 归纳偏好

对于一个具体的学习算法，**必须**要产生一个模型。这时，学习算法本身的“偏好”就会起到关键的作用。

机器学习算法在学习过程中对某种类型假设的偏好，称为“归纳 偏好”（inductive bias），或简称为“偏好”。
任何一个有效的机器学习算法必有其归纳偏好，否则它将被假设空间中看似在训练集上“等效”的假设所迷惑，而无法产生确定的学习结果。

奥卡姆剃刀本身存在不同的诠释，使用奥卡姆剃刀原则**并不平凡**。

NFL的前提：所有“问题”出现的机会相同、或所有问题同等重要。
